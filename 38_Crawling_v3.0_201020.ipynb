{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from itertools import count\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_dir='C:/Yeajin/리얼데이터/마일스톤/chromedriver_win32/chromedriver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling_38():\n",
    "    import pandas as pd\n",
    "    url_apply='http://www.38.co.kr/html/ipo/ipo.htm?o=&key=2&page='\n",
    "    \n",
    "    d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "    print(d)\n",
    "    print('청구종목 크롤링을 시작하겠습니다.')\n",
    "\n",
    "    demand_datelist=[]       # 청구일\n",
    "    namelist=[]       # 회사명\n",
    "    statuslist=[]     # 승인상태\n",
    "    capitallist=[]    # 자본금(백만)\n",
    "    saleslist=[]      # 매출액(백만)\n",
    "    netincomelist=[]  # 당기순이익(백만)\n",
    "    companylist=[]    # 주간사\n",
    "    bizlist=[]        # 주업종\n",
    "\n",
    "\n",
    "    for p in count(1):\n",
    "        try:\n",
    "            newurl=url_apply+str(p)\n",
    "            driver.get(newurl)\n",
    "            html=driver.page_source\n",
    "            soup=BeautifulSoup(html,'html.parser')\n",
    "            print('현재 ',p,'페이지 크롤링 중입니다.')\n",
    "\n",
    "            for i in range(1,31):\n",
    "                demand_date=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[{1}]').text\n",
    "                name=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[2]').text\n",
    "                status=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[3]').text\n",
    "                capital=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[4]').text\n",
    "                sales=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[5]').text\n",
    "                netincome=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[6]').text\n",
    "                company=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[7]').text\n",
    "                biz=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[8]').text\n",
    "\n",
    "\n",
    "\n",
    "                demand_datelist.append(demand_date)\n",
    "                namelist.append(name)\n",
    "                statuslist.append(status)\n",
    "                capitallist.append(capital)\n",
    "                saleslist.append(sales)\n",
    "                netincomelist.append(netincome)\n",
    "                companylist.append(company)\n",
    "                bizlist.append(biz)\n",
    "\n",
    "\n",
    "\n",
    "        except:\n",
    "                d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "                print(d,'기준으로 총 ',p,'페이지의 청구종목을 크롤링했습니다.')\n",
    "                break\n",
    "\n",
    "\n",
    "    mCols=[]\n",
    "    apply_df=pd.DataFrame(columns=mCols)\n",
    "\n",
    "    apply_df['청구일']=demand_datelist\n",
    "    apply_df['기업명']=namelist\n",
    "    apply_df['상태']=statuslist\n",
    "    apply_df['자본금(백만)']=capitallist\n",
    "    apply_df['매출액(백만)']=saleslist\n",
    "    apply_df['당기순이익(백만)']=netincomelist\n",
    "    apply_df['주간사']=companylist\n",
    "    apply_df['주업종']=bizlist\n",
    "\n",
    "    apply_df.to_csv('청구종목.csv',encoding='utf-8')\n",
    "    \n",
    "    # 승인종목 크롤링\n",
    "    url_approval='http://www.38.co.kr/html/ipo/ipo.htm?o=&key=1&page='\n",
    "\n",
    "    d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "    print('----------------------------------------------------------------------')\n",
    "    print(d)\n",
    "    print('승인종목 크롤링을 시작하겠습니다.')\n",
    "\n",
    "    approve_datelist=[]       # 승인일\n",
    "    namelist=[]               # 기업명\n",
    "    demand_datelist=[]        # 청구일\n",
    "    capitallist=[]    # 자본금(백만)\n",
    "    saleslist=[]      # 매출액(백만)\n",
    "    netincomelist=[]  # 당기순이익(백만)\n",
    "    companylist=[]    # 주간사\n",
    "    bizlist=[]        # 주업종\n",
    "\n",
    "\n",
    "    for p in count(1):\n",
    "        try:\n",
    "            newurl=url_approval+str(p)\n",
    "            driver.get(newurl)\n",
    "            html=driver.page_source\n",
    "            soup=BeautifulSoup(html,'html.parser')\n",
    "            print('현재 ',p,'페이지 크롤링 중입니다.')\n",
    "\n",
    "#            for i in range(1,31):\n",
    "#                 approve_date=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[1]').text\n",
    "#                 name=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[2]').text\n",
    "#                 demand_date=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[3]').text\n",
    "#                 capital=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[4]').text\n",
    "#                 sales=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[5]').text\n",
    "#                 netincome=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[6]').text\n",
    "#                 company=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[7]').text\n",
    "#                 biz=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[8]').text\n",
    "            for i in range(1,31):\n",
    "        \n",
    "                approve_date=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[1]').text\n",
    "                name=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[2]').text\n",
    "                demand_date=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[3]').text\n",
    "                capital=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[4]').text\n",
    "                sales=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[5]').text\n",
    "                netincome=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[6]').text\n",
    "                company=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[7]').text\n",
    "                biz=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[5]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[8]').text\n",
    "\n",
    "\n",
    "\n",
    "                approve_datelist.append(approve_date)\n",
    "                namelist.append(name)\n",
    "                demand_datelist.append(demand_date)\n",
    "                capitallist.append(capital)\n",
    "                saleslist.append(sales)\n",
    "                netincomelist.append(netincome)\n",
    "                companylist.append(company)\n",
    "                bizlist.append(biz)\n",
    "\n",
    "\n",
    "\n",
    "        except:\n",
    "                d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "                print(d,'기준으로 총 ',p,'페이지의 승인종목을 크롤링했습니다.')\n",
    "                break\n",
    "                \n",
    "    mCols=[]\n",
    "    approval_df=pd.DataFrame(columns=mCols)\n",
    "\n",
    "    approval_df['승인일']=approve_datelist\n",
    "    approval_df['기업명']=namelist\n",
    "    approval_df['청구일']=demand_datelist\n",
    "    approval_df['자본금(백만)']=capitallist\n",
    "    approval_df['매출액(백만)']=saleslist\n",
    "    approval_df['당기순이익(백만)']=netincomelist\n",
    "    approval_df['주간사']=companylist\n",
    "    approval_df['주업종']=bizlist    \n",
    "    \n",
    "    approval_df.to_csv('승인종목.csv',encoding='utf-8')\n",
    "    \n",
    "    \n",
    "    # 기업 IR 일정 크롤링\n",
    "    url_ir='http://www.38.co.kr/html/fund/index.htm?o=ir&page='\n",
    "\n",
    "    print('----------------------------------------------------------------------')\n",
    "    d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "    print(d)\n",
    "    print('기업 IR 일정 크롤링을 시작하겠습니다.')\n",
    "\n",
    "    namelist=[]       # 회사명\n",
    "    ir_datelist=[]    # IR 일자\n",
    "    placetimelist=[]     # IR 장소/시간\n",
    "    desired_pricelist=[]    # 공모희망가\n",
    "    companylist=[]    # 주간사\n",
    "\n",
    "\n",
    "    for p in count(1):\n",
    "        try:\n",
    "            newurl=url_ir+str(p)\n",
    "            driver.get(newurl)\n",
    "            html=driver.page_source\n",
    "            soup=BeautifulSoup(html,'html.parser')\n",
    "            print('현재 ',p,'페이지 크롤링 중입니다.')\n",
    "\n",
    "            for i in range(1,21):\n",
    "                name=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[1]').text\n",
    "                ir_date=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[2]').text\n",
    "                placetime=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[3]').text\n",
    "                desired_price=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[4]').text\n",
    "                company=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[5]').text\n",
    "\n",
    "\n",
    "\n",
    "                namelist.append(name)\n",
    "                ir_datelist.append(ir_date)\n",
    "                placetimelist.append(placetime)\n",
    "                desired_pricelist.append(desired_price)\n",
    "                companylist.append(company)\n",
    "\n",
    "\n",
    "\n",
    "        except:\n",
    "                d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "                print(d,'기준으로 총 ',p,'페이지의 기업 IR 일정을 크롤링했습니다.')\n",
    "                break\n",
    "\n",
    "    mCols=[]\n",
    "    ir_df=pd.DataFrame(columns=mCols)\n",
    "\n",
    "    ir_df['기업명']=namelist\n",
    "    ir_df['IR 일자']=ir_datelist\n",
    "    ir_df['IR 장소/시간']=placetimelist\n",
    "    ir_df['공모희망가']=desired_pricelist\n",
    "    ir_df['주간사']=companylist\n",
    "\n",
    "    ir_df.to_csv('기업 IR 일정.csv',encoding='utf-8')\n",
    "    \n",
    "    \n",
    "    \n",
    "        # 수요예측일정 크롤링\n",
    "    url_demand='http://www.38.co.kr/html/fund/index.htm?o=r&page='\n",
    "\n",
    "    d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "    print('----------------------------------------------------------------------')\n",
    "    print(d)\n",
    "    print('수요예측일정 크롤링을 시작하겠습니다.')\n",
    "\n",
    "    namelist=[]              # 회사명\n",
    "    demand_schedulelist=[]   # 수요예측일정\n",
    "    desired_pricelist=[]     # 희망공모가(원)\n",
    "    confirmed_pricelist=[]   # 확정공모가(원)\n",
    "    pricelist=[]             # 공모금액(백만)\n",
    "    companylist=[]           # 주간사\n",
    "\n",
    "\n",
    "    for p in count(1):\n",
    "        try:\n",
    "            newurl=url_demand+str(p)\n",
    "            driver.get(newurl)\n",
    "            html=driver.page_source\n",
    "            soup=BeautifulSoup(html,'html.parser')\n",
    "            print('현재 ',p,'페이지 크롤링 중입니다.')\n",
    "\n",
    "            for i in range(1,21):\n",
    "                name=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[{1}]').text\n",
    "                demand_schedule=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[{2}]').text\n",
    "                desired_price=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[{3}]').text\n",
    "                confirmed_price=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[{4}]').text\n",
    "                price=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[{5}]').text\n",
    "                company=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[{6}]').text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                namelist.append(name)\n",
    "                demand_schedulelist.append(demand_schedule)\n",
    "                desired_pricelist.append(desired_price)\n",
    "                confirmed_pricelist.append(confirmed_price)\n",
    "                pricelist.append(price)\n",
    "                companylist.append(company)\n",
    "\n",
    "        except:\n",
    "                d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "                print(d,'기준으로 총 ',p,'페이지의 수요예측일정을 크롤링했습니다.')\n",
    "                break\n",
    "\n",
    "    mCols=[]\n",
    "    demand_schedule_df=pd.DataFrame(columns=mCols)\n",
    "\n",
    "    demand_schedule_df['기업명']=namelist\n",
    "    demand_schedule_df['수요예측일']=demand_schedulelist\n",
    "    demand_schedule_df['희망공모가(원)']=desired_pricelist\n",
    "    demand_schedule_df['확정공모가']=confirmed_pricelist\n",
    "    demand_schedule_df['공모금액(백만)']=pricelist\n",
    "    demand_schedule_df['주간사']=companylist\n",
    "\n",
    "    demand_schedule_df.to_csv('수요예측일정.csv',encoding='utf-8')\n",
    "    \n",
    "    \n",
    "    # 수요예측결과 크롤링\n",
    "    url_result='http://www.38.co.kr/html/fund/index.htm?o=r1&page='\n",
    "\n",
    "    print('----------------------------------------------------------------------')\n",
    "    d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "    print(d)\n",
    "    print('수요예측결과 크롤링을 시작하겠습니다.')\n",
    "\n",
    "    namelist=[]             # 회사명\n",
    "    predict_datelist=[]     # 예측일\n",
    "    desired_pricelist=[]    # 공모희망가\n",
    "    price_resultlist=[]     # 공모가\n",
    "    pricelist=[]            # 공모금액\n",
    "    competitionlist=[]      # 기관경쟁률\n",
    "    commitmentlist=[]       # 의무보유확약\n",
    "    companylist=[]          # 주간사\n",
    "\n",
    "\n",
    "    for p in count(1):\n",
    "        try:\n",
    "            newurl=url_result+str(p)\n",
    "            driver.get(newurl)\n",
    "            html=driver.page_source\n",
    "            soup=BeautifulSoup(html,'html.parser')\n",
    "            print('현재 ',p,'페이지 크롤링 중입니다.')\n",
    "\n",
    "            for i in range(1,21):\n",
    "                name=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[1]').text\n",
    "                predict_date=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[2]').text\n",
    "                desired_price=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[3]').text\n",
    "                price_result=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[4]').text\n",
    "                price=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[5]').text\n",
    "                competition=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[6]').text\n",
    "                commitment=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[7]').text\n",
    "                company=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[8]').text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                namelist.append(name)\n",
    "                predict_datelist.append(predict_date)\n",
    "                desired_pricelist.append(desired_price)\n",
    "                price_resultlist.append(price_result)\n",
    "                pricelist.append(price)\n",
    "                competitionlist.append(competition)\n",
    "                commitmentlist.append(commitment)\n",
    "                companylist.append(company)\n",
    "\n",
    "\n",
    "\n",
    "        except:\n",
    "                d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "                print(d,'기준으로 총 ',p,'페이지의 수요예측결과를 크롤링했습니다.')\n",
    "                break\n",
    "\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    mCols=[]\n",
    "    result_df=pd.DataFrame(columns=mCols)\n",
    "\n",
    "    result_df['기업명']=namelist\n",
    "    result_df['예측일']=predict_datelist\n",
    "    result_df['공모희망가(원)']=desired_pricelist\n",
    "    result_df['공모가(원)']=price_resultlist\n",
    "    result_df['공모금액(백만원)']=pricelist\n",
    "    result_df['기관경쟁률']=competitionlist\n",
    "    result_df['의무보유확약']=commitmentlist\n",
    "    result_df['주간사']=companylist\n",
    "    \n",
    "    result_df.to_csv('수요예측결과.csv',encoding='utf-8')\n",
    "    \n",
    "    # 공모청약일정 크롤링\n",
    "    url_subs='http://www.38.co.kr/html/fund/index.htm?o=k&page='\n",
    "\n",
    "    d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "    print('----------------------------------------------------------------------')\n",
    "    print(d)\n",
    "    print('공모청약일정 크롤링을 시작하겠습니다.')\n",
    "\n",
    "    itemlist=[]              # 종목명\n",
    "    public_schedulelist=[]   # 공모주일정\n",
    "    confirmed_pricelist=[]   # 확정공모가\n",
    "    desired_pricelist=[]     # 희망공모가\n",
    "    subscription_competitionlist=[]     # 청약경쟁률\n",
    "    companylist=[]           # 주간사\n",
    "    analysislist=[]          # 분석 링크\n",
    "\n",
    "\n",
    "\n",
    "    for p in count(1):\n",
    "        try:\n",
    "            newurl=url_subs+str(p)\n",
    "            driver.get(newurl)\n",
    "            html=driver.page_source\n",
    "            soup=BeautifulSoup(html,'html.parser')\n",
    "            print('현재 ',p,'페이지 크롤링 중입니다.')\n",
    "\n",
    "            for i in range(1,26):\n",
    "                item=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[1]').text\n",
    "                public_schedule=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[2]').text\n",
    "                confirmed_price=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[3]').text\n",
    "                desired_price=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[4]').text\n",
    "                subscription_competition=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[5]').text\n",
    "                company=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[6]').text\n",
    "                analysis=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[7]/a')\n",
    "                analysis=analysis.get_attribute('href')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                itemlist.append(item)\n",
    "                public_schedulelist.append(public_schedule)\n",
    "                confirmed_pricelist.append(confirmed_price)\n",
    "                desired_pricelist.append(desired_price)\n",
    "                subscription_competitionlist.append(subscription_competition)\n",
    "                companylist.append(company)\n",
    "                analysislist.append(analysis)\n",
    "\n",
    "\n",
    "\n",
    "        except:\n",
    "                d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "                print(d,'기준으로 총 ',p,'페이지의 공모청약일정을 크롤링했습니다.')\n",
    "                break\n",
    "    \n",
    "    mCols=[]\n",
    "    subscription_df=pd.DataFrame(columns=mCols)\n",
    "\n",
    "    subscription_df['기업명']=itemlist\n",
    "    subscription_df['공모주일정']=public_schedulelist\n",
    "    subscription_df['확정공모가']=confirmed_pricelist\n",
    "    subscription_df['희망공모가']=desired_pricelist\n",
    "    subscription_df['청약경쟁률']=subscription_competitionlist\n",
    "    subscription_df['주간사']=companylist\n",
    "    subscription_df['분석링크']=analysislist\n",
    "    \n",
    "    subscription_df.to_csv('공모청약일정.csv',encoding='utf-8')\n",
    "    \n",
    "  # 신규상장 크롤링\n",
    "    url_new='http://www.38.co.kr/html/fund/index.htm?o=nw&page='\n",
    "\n",
    "    d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "    print('----------------------------------------------------------------------')\n",
    "    print(d)\n",
    "    print('신규상장 크롤링을 시작하겠습니다.')\n",
    "\n",
    "    namelist=[]                    # 회사명\n",
    "    newlisting_datelist=[]         # 신규상장일\n",
    "    present_pricelist=[]           # 현재가\n",
    "    comparisonlist=[]              # 전일비\n",
    "    offering_pricelist=[]          # 공모가\n",
    "    fluctuationlist=[]             # 공모가대비 등락률\n",
    "    opening_pricelist=[]           # 시초가\n",
    "    opening_offeringlist=[]        # 시초/공모\n",
    "    first_closinglist=[]           # 첫날종가\n",
    "\n",
    "\n",
    "\n",
    "    for p in count(1):\n",
    "        try:\n",
    "            newurl=url_new+str(p)\n",
    "            driver.get(newurl)\n",
    "            html=driver.page_source\n",
    "            soup=BeautifulSoup(html,'html.parser')\n",
    "            \n",
    "            print('현재 ',p,'페이지 크롤링 중입니다.')\n",
    "\n",
    "            for i in range(1,21):\n",
    "                name=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[1]').text\n",
    "                newlisting_date=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[2]').text\n",
    "                present_price=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[3]').text\n",
    "                comparison=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[4]').text\n",
    "                offering_price=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[5]').text\n",
    "                fluctuation=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[6]').text\n",
    "                opening_price=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[7]').text\n",
    "                opening_offering=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[8]').text\n",
    "                first_closing=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[9]').text\n",
    "\n",
    "\n",
    "\n",
    "                namelist.append(name)\n",
    "                newlisting_datelist.append(newlisting_date)\n",
    "                present_pricelist.append(present_price)\n",
    "                comparisonlist.append(comparison)\n",
    "                offering_pricelist.append(offering_price)\n",
    "                fluctuationlist.append(fluctuation)\n",
    "                opening_pricelist.append(opening_price)\n",
    "                opening_offeringlist.append(opening_offering)\n",
    "                first_closinglist.append(first_closing)\n",
    "\n",
    "\n",
    "\n",
    "        except:\n",
    "                d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "                print(d,'기준으로 총 ',p,'페이지의 신규상장 목록을 크롤링했습니다.')\n",
    "                break\n",
    "                \n",
    "            \n",
    "\n",
    "    mCols=[]\n",
    "    newlisting_df=pd.DataFrame(columns=mCols)\n",
    "\n",
    "    newlisting_df['기업명']=namelist\n",
    "    newlisting_df['신규상장일']=newlisting_datelist\n",
    "    newlisting_df['현재가(원)']=present_pricelist\n",
    "    newlisting_df['전일비(%)']=comparisonlist\n",
    "    newlisting_df['공모가(원)']=offering_pricelist\n",
    "    newlisting_df['공모가대비등락률(%)']=fluctuationlist\n",
    "    newlisting_df['시초가(원)']=opening_pricelist\n",
    "    newlisting_df['시초/공모(%)']=opening_offeringlist\n",
    "    newlisting_df['첫날종가(원)']=first_closinglist\n",
    "    \n",
    "    newlisting_df.to_csv('신규상장.csv',encoding='utf-8')\n",
    "    \n",
    "    d=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "    print(d,'기준으로 모든 항목의 크롤링이 완료되었습니다.')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-20 09:31:08\n",
      "청구종목 크롤링을 시작하겠습니다.\n",
      "현재  1 페이지 크롤링 중입니다.\n",
      "현재  2 페이지 크롤링 중입니다.\n",
      "2020-10-20 09:31:25 기준으로 총  2 페이지의 청구종목을 크롤링했습니다.\n",
      "----------------------------------------------------------------------\n",
      "2020-10-20 09:31:25\n",
      "승인종목 크롤링을 시작하겠습니다.\n",
      "현재  1 페이지 크롤링 중입니다.\n",
      "현재  2 페이지 크롤링 중입니다.\n",
      "2020-10-20 09:31:32 기준으로 총  2 페이지의 승인종목을 크롤링했습니다.\n",
      "----------------------------------------------------------------------\n",
      "2020-10-20 09:31:32\n",
      "기업 IR 일정 크롤링을 시작하겠습니다.\n",
      "현재  1 페이지 크롤링 중입니다.\n",
      "현재  2 페이지 크롤링 중입니다.\n",
      "현재  3 페이지 크롤링 중입니다.\n",
      "현재  4 페이지 크롤링 중입니다.\n",
      "현재  5 페이지 크롤링 중입니다.\n",
      "현재  6 페이지 크롤링 중입니다.\n",
      "현재  7 페이지 크롤링 중입니다.\n",
      "현재  8 페이지 크롤링 중입니다.\n",
      "현재  9 페이지 크롤링 중입니다.\n",
      "현재  10 페이지 크롤링 중입니다.\n",
      "현재  11 페이지 크롤링 중입니다.\n",
      "현재  12 페이지 크롤링 중입니다.\n",
      "현재  13 페이지 크롤링 중입니다.\n",
      "현재  14 페이지 크롤링 중입니다.\n",
      "현재  15 페이지 크롤링 중입니다.\n",
      "현재  16 페이지 크롤링 중입니다.\n",
      "현재  17 페이지 크롤링 중입니다.\n",
      "현재  18 페이지 크롤링 중입니다.\n",
      "현재  19 페이지 크롤링 중입니다.\n",
      "현재  20 페이지 크롤링 중입니다.\n",
      "현재  21 페이지 크롤링 중입니다.\n",
      "현재  22 페이지 크롤링 중입니다.\n",
      "현재  23 페이지 크롤링 중입니다.\n",
      "현재  24 페이지 크롤링 중입니다.\n",
      "현재  25 페이지 크롤링 중입니다.\n",
      "현재  26 페이지 크롤링 중입니다.\n",
      "현재  27 페이지 크롤링 중입니다.\n",
      "현재  28 페이지 크롤링 중입니다.\n",
      "현재  29 페이지 크롤링 중입니다.\n",
      "현재  30 페이지 크롤링 중입니다.\n",
      "현재  31 페이지 크롤링 중입니다.\n",
      "현재  32 페이지 크롤링 중입니다.\n",
      "현재  33 페이지 크롤링 중입니다.\n",
      "현재  34 페이지 크롤링 중입니다.\n",
      "현재  35 페이지 크롤링 중입니다.\n",
      "현재  36 페이지 크롤링 중입니다.\n",
      "현재  37 페이지 크롤링 중입니다.\n",
      "현재  38 페이지 크롤링 중입니다.\n",
      "현재  39 페이지 크롤링 중입니다.\n",
      "현재  40 페이지 크롤링 중입니다.\n",
      "현재  41 페이지 크롤링 중입니다.\n",
      "현재  42 페이지 크롤링 중입니다.\n",
      "2020-10-20 09:33:31 기준으로 총  42 페이지의 기업 IR 일정을 크롤링했습니다.\n",
      "----------------------------------------------------------------------\n",
      "2020-10-20 09:33:31\n",
      "수요예측일정 크롤링을 시작하겠습니다.\n",
      "현재  1 페이지 크롤링 중입니다.\n",
      "현재  2 페이지 크롤링 중입니다.\n",
      "현재  3 페이지 크롤링 중입니다.\n",
      "현재  4 페이지 크롤링 중입니다.\n",
      "현재  5 페이지 크롤링 중입니다.\n",
      "현재  6 페이지 크롤링 중입니다.\n",
      "현재  7 페이지 크롤링 중입니다.\n",
      "현재  8 페이지 크롤링 중입니다.\n",
      "현재  9 페이지 크롤링 중입니다.\n",
      "현재  10 페이지 크롤링 중입니다.\n",
      "현재  11 페이지 크롤링 중입니다.\n",
      "현재  12 페이지 크롤링 중입니다.\n",
      "현재  13 페이지 크롤링 중입니다.\n",
      "현재  14 페이지 크롤링 중입니다.\n",
      "현재  15 페이지 크롤링 중입니다.\n",
      "현재  16 페이지 크롤링 중입니다.\n",
      "현재  17 페이지 크롤링 중입니다.\n",
      "현재  18 페이지 크롤링 중입니다.\n",
      "현재  19 페이지 크롤링 중입니다.\n",
      "현재  20 페이지 크롤링 중입니다.\n",
      "현재  21 페이지 크롤링 중입니다.\n",
      "현재  22 페이지 크롤링 중입니다.\n",
      "현재  23 페이지 크롤링 중입니다.\n",
      "현재  24 페이지 크롤링 중입니다.\n",
      "현재  25 페이지 크롤링 중입니다.\n",
      "현재  26 페이지 크롤링 중입니다.\n",
      "현재  27 페이지 크롤링 중입니다.\n",
      "현재  28 페이지 크롤링 중입니다.\n",
      "현재  29 페이지 크롤링 중입니다.\n",
      "현재  30 페이지 크롤링 중입니다.\n",
      "현재  31 페이지 크롤링 중입니다.\n",
      "현재  32 페이지 크롤링 중입니다.\n",
      "현재  33 페이지 크롤링 중입니다.\n",
      "현재  34 페이지 크롤링 중입니다.\n",
      "현재  35 페이지 크롤링 중입니다.\n",
      "현재  36 페이지 크롤링 중입니다.\n",
      "현재  37 페이지 크롤링 중입니다.\n",
      "현재  38 페이지 크롤링 중입니다.\n",
      "현재  39 페이지 크롤링 중입니다.\n",
      "현재  40 페이지 크롤링 중입니다.\n",
      "현재  41 페이지 크롤링 중입니다.\n",
      "현재  42 페이지 크롤링 중입니다.\n",
      "현재  43 페이지 크롤링 중입니다.\n",
      "현재  44 페이지 크롤링 중입니다.\n",
      "현재  45 페이지 크롤링 중입니다.\n",
      "현재  46 페이지 크롤링 중입니다.\n",
      "현재  47 페이지 크롤링 중입니다.\n",
      "현재  48 페이지 크롤링 중입니다.\n",
      "현재  49 페이지 크롤링 중입니다.\n",
      "현재  50 페이지 크롤링 중입니다.\n",
      "현재  51 페이지 크롤링 중입니다.\n",
      "현재  52 페이지 크롤링 중입니다.\n",
      "현재  53 페이지 크롤링 중입니다.\n",
      "현재  54 페이지 크롤링 중입니다.\n",
      "현재  55 페이지 크롤링 중입니다.\n",
      "현재  56 페이지 크롤링 중입니다.\n",
      "현재  57 페이지 크롤링 중입니다.\n",
      "현재  58 페이지 크롤링 중입니다.\n",
      "현재  59 페이지 크롤링 중입니다.\n",
      "현재  60 페이지 크롤링 중입니다.\n",
      "현재  61 페이지 크롤링 중입니다.\n",
      "2020-10-20 09:37:02 기준으로 총  61 페이지의 수요예측일정을 크롤링했습니다.\n",
      "----------------------------------------------------------------------\n",
      "2020-10-20 09:37:02\n",
      "수요예측결과 크롤링을 시작하겠습니다.\n",
      "현재  1 페이지 크롤링 중입니다.\n",
      "현재  2 페이지 크롤링 중입니다.\n",
      "현재  3 페이지 크롤링 중입니다.\n",
      "현재  4 페이지 크롤링 중입니다.\n",
      "현재  5 페이지 크롤링 중입니다.\n",
      "현재  6 페이지 크롤링 중입니다.\n",
      "현재  7 페이지 크롤링 중입니다.\n",
      "현재  8 페이지 크롤링 중입니다.\n",
      "현재  9 페이지 크롤링 중입니다.\n",
      "현재  10 페이지 크롤링 중입니다.\n",
      "현재  11 페이지 크롤링 중입니다.\n",
      "현재  12 페이지 크롤링 중입니다.\n",
      "현재  13 페이지 크롤링 중입니다.\n",
      "현재  14 페이지 크롤링 중입니다.\n",
      "현재  15 페이지 크롤링 중입니다.\n",
      "현재  16 페이지 크롤링 중입니다.\n",
      "현재  17 페이지 크롤링 중입니다.\n",
      "현재  18 페이지 크롤링 중입니다.\n",
      "현재  19 페이지 크롤링 중입니다.\n",
      "현재  20 페이지 크롤링 중입니다.\n",
      "현재  21 페이지 크롤링 중입니다.\n",
      "현재  22 페이지 크롤링 중입니다.\n",
      "현재  23 페이지 크롤링 중입니다.\n",
      "현재  24 페이지 크롤링 중입니다.\n",
      "현재  25 페이지 크롤링 중입니다.\n",
      "현재  26 페이지 크롤링 중입니다.\n",
      "현재  27 페이지 크롤링 중입니다.\n",
      "현재  28 페이지 크롤링 중입니다.\n",
      "현재  29 페이지 크롤링 중입니다.\n",
      "현재  30 페이지 크롤링 중입니다.\n",
      "현재  31 페이지 크롤링 중입니다.\n",
      "현재  32 페이지 크롤링 중입니다.\n",
      "현재  33 페이지 크롤링 중입니다.\n",
      "현재  34 페이지 크롤링 중입니다.\n",
      "현재  35 페이지 크롤링 중입니다.\n",
      "현재  36 페이지 크롤링 중입니다.\n",
      "현재  37 페이지 크롤링 중입니다.\n",
      "현재  38 페이지 크롤링 중입니다.\n",
      "현재  39 페이지 크롤링 중입니다.\n",
      "현재  40 페이지 크롤링 중입니다.\n",
      "현재  41 페이지 크롤링 중입니다.\n",
      "현재  42 페이지 크롤링 중입니다.\n",
      "현재  43 페이지 크롤링 중입니다.\n",
      "현재  44 페이지 크롤링 중입니다.\n",
      "현재  45 페이지 크롤링 중입니다.\n",
      "현재  46 페이지 크롤링 중입니다.\n",
      "현재  47 페이지 크롤링 중입니다.\n",
      "현재  48 페이지 크롤링 중입니다.\n",
      "현재  49 페이지 크롤링 중입니다.\n",
      "현재  50 페이지 크롤링 중입니다.\n",
      "현재  51 페이지 크롤링 중입니다.\n",
      "현재  52 페이지 크롤링 중입니다.\n",
      "현재  53 페이지 크롤링 중입니다.\n",
      "현재  54 페이지 크롤링 중입니다.\n",
      "현재  55 페이지 크롤링 중입니다.\n",
      "현재  56 페이지 크롤링 중입니다.\n",
      "현재  57 페이지 크롤링 중입니다.\n",
      "현재  58 페이지 크롤링 중입니다.\n",
      "현재  59 페이지 크롤링 중입니다.\n",
      "현재  60 페이지 크롤링 중입니다.\n",
      "2020-10-20 09:41:30 기준으로 총  60 페이지의 수요예측결과를 크롤링했습니다.\n",
      "----------------------------------------------------------------------\n",
      "2020-10-20 09:41:30\n",
      "공모청약일정 크롤링을 시작하겠습니다.\n",
      "현재  1 페이지 크롤링 중입니다.\n",
      "현재  2 페이지 크롤링 중입니다.\n",
      "현재  3 페이지 크롤링 중입니다.\n",
      "현재  4 페이지 크롤링 중입니다.\n",
      "현재  5 페이지 크롤링 중입니다.\n",
      "현재  6 페이지 크롤링 중입니다.\n",
      "현재  7 페이지 크롤링 중입니다.\n",
      "현재  8 페이지 크롤링 중입니다.\n",
      "현재  9 페이지 크롤링 중입니다.\n",
      "현재  10 페이지 크롤링 중입니다.\n",
      "현재  11 페이지 크롤링 중입니다.\n",
      "현재  12 페이지 크롤링 중입니다.\n",
      "현재  13 페이지 크롤링 중입니다.\n",
      "현재  14 페이지 크롤링 중입니다.\n",
      "현재  15 페이지 크롤링 중입니다.\n",
      "현재  16 페이지 크롤링 중입니다.\n",
      "현재  17 페이지 크롤링 중입니다.\n",
      "현재  18 페이지 크롤링 중입니다.\n",
      "현재  19 페이지 크롤링 중입니다.\n",
      "현재  20 페이지 크롤링 중입니다.\n",
      "현재  21 페이지 크롤링 중입니다.\n",
      "현재  22 페이지 크롤링 중입니다.\n",
      "현재  23 페이지 크롤링 중입니다.\n",
      "현재  24 페이지 크롤링 중입니다.\n",
      "현재  25 페이지 크롤링 중입니다.\n",
      "현재  26 페이지 크롤링 중입니다.\n",
      "현재  27 페이지 크롤링 중입니다.\n",
      "현재  28 페이지 크롤링 중입니다.\n",
      "현재  29 페이지 크롤링 중입니다.\n",
      "현재  30 페이지 크롤링 중입니다.\n",
      "현재  31 페이지 크롤링 중입니다.\n",
      "현재  32 페이지 크롤링 중입니다.\n",
      "현재  33 페이지 크롤링 중입니다.\n",
      "현재  34 페이지 크롤링 중입니다.\n",
      "현재  35 페이지 크롤링 중입니다.\n",
      "현재  36 페이지 크롤링 중입니다.\n",
      "현재  37 페이지 크롤링 중입니다.\n",
      "현재  38 페이지 크롤링 중입니다.\n",
      "현재  39 페이지 크롤링 중입니다.\n",
      "현재  40 페이지 크롤링 중입니다.\n",
      "현재  41 페이지 크롤링 중입니다.\n",
      "현재  42 페이지 크롤링 중입니다.\n",
      "현재  43 페이지 크롤링 중입니다.\n",
      "현재  44 페이지 크롤링 중입니다.\n",
      "현재  45 페이지 크롤링 중입니다.\n",
      "현재  46 페이지 크롤링 중입니다.\n",
      "현재  47 페이지 크롤링 중입니다.\n",
      "현재  48 페이지 크롤링 중입니다.\n",
      "현재  49 페이지 크롤링 중입니다.\n",
      "2020-10-20 09:45:14 기준으로 총  49 페이지의 공모청약일정을 크롤링했습니다.\n",
      "----------------------------------------------------------------------\n",
      "2020-10-20 09:45:14\n",
      "신규상장 크롤링을 시작하겠습니다.\n",
      "현재  1 페이지 크롤링 중입니다.\n",
      "현재  2 페이지 크롤링 중입니다.\n",
      "현재  3 페이지 크롤링 중입니다.\n",
      "현재  4 페이지 크롤링 중입니다.\n",
      "현재  5 페이지 크롤링 중입니다.\n",
      "현재  6 페이지 크롤링 중입니다.\n",
      "현재  7 페이지 크롤링 중입니다.\n",
      "현재  8 페이지 크롤링 중입니다.\n",
      "현재  9 페이지 크롤링 중입니다.\n",
      "현재  10 페이지 크롤링 중입니다.\n",
      "현재  11 페이지 크롤링 중입니다.\n",
      "현재  12 페이지 크롤링 중입니다.\n",
      "현재  13 페이지 크롤링 중입니다.\n",
      "현재  14 페이지 크롤링 중입니다.\n",
      "현재  15 페이지 크롤링 중입니다.\n",
      "현재  16 페이지 크롤링 중입니다.\n",
      "현재  17 페이지 크롤링 중입니다.\n",
      "현재  18 페이지 크롤링 중입니다.\n",
      "현재  19 페이지 크롤링 중입니다.\n",
      "현재  20 페이지 크롤링 중입니다.\n",
      "현재  21 페이지 크롤링 중입니다.\n",
      "현재  22 페이지 크롤링 중입니다.\n",
      "현재  23 페이지 크롤링 중입니다.\n",
      "현재  24 페이지 크롤링 중입니다.\n",
      "현재  25 페이지 크롤링 중입니다.\n",
      "현재  26 페이지 크롤링 중입니다.\n",
      "현재  27 페이지 크롤링 중입니다.\n",
      "현재  28 페이지 크롤링 중입니다.\n",
      "현재  29 페이지 크롤링 중입니다.\n",
      "현재  30 페이지 크롤링 중입니다.\n",
      "현재  31 페이지 크롤링 중입니다.\n",
      "현재  32 페이지 크롤링 중입니다.\n",
      "현재  33 페이지 크롤링 중입니다.\n",
      "현재  34 페이지 크롤링 중입니다.\n",
      "현재  35 페이지 크롤링 중입니다.\n",
      "현재  36 페이지 크롤링 중입니다.\n",
      "현재  37 페이지 크롤링 중입니다.\n",
      "현재  38 페이지 크롤링 중입니다.\n",
      "현재  39 페이지 크롤링 중입니다.\n",
      "현재  40 페이지 크롤링 중입니다.\n",
      "현재  41 페이지 크롤링 중입니다.\n",
      "현재  42 페이지 크롤링 중입니다.\n",
      "현재  43 페이지 크롤링 중입니다.\n",
      "현재  44 페이지 크롤링 중입니다.\n",
      "현재  45 페이지 크롤링 중입니다.\n",
      "현재  46 페이지 크롤링 중입니다.\n",
      "현재  47 페이지 크롤링 중입니다.\n",
      "현재  48 페이지 크롤링 중입니다.\n",
      "현재  49 페이지 크롤링 중입니다.\n",
      "현재  50 페이지 크롤링 중입니다.\n",
      "현재  51 페이지 크롤링 중입니다.\n",
      "현재  52 페이지 크롤링 중입니다.\n",
      "현재  53 페이지 크롤링 중입니다.\n",
      "현재  54 페이지 크롤링 중입니다.\n",
      "현재  55 페이지 크롤링 중입니다.\n",
      "2020-10-20 09:49:51 기준으로 총  55 페이지의 신규상장 목록을 크롤링했습니다.\n",
      "2020-10-20 09:49:51 기준으로 모든 항목의 크롤링이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(chrome_dir)\n",
    "crawling_38()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
