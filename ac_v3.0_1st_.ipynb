{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 성근 note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from itertools import count\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import numpy as np\n",
    "\n",
    "# import glob\n",
    "# from pyexcel.cookbook import merge_all_to_a_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_dir='C:/Yeajin/chromedriver_win32/chromedriver'\n",
    "save_dir='C:/Yeajin/리얼데이터/마일스톤/crawling/'\n",
    "\n",
    "pstock_url='http://www.pstock.co.kr/2005pstock/main.asp'\n",
    "naver_url='https://finance.naver.com/item/main.nhn?code='\n",
    "url_38='http://www.38.co.kr/html/fund/index.htm?o=nw&page='\n",
    "\n",
    "df_dtype={'code':str} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial search list with code\n",
    "\n",
    "def create_initial_search_list():\n",
    "    code_list=[]\n",
    "    name_list=[]\n",
    "\n",
    "    for p in count(1): # 38에서 페이지# iteration \n",
    "        try:\n",
    "            url=url_38+str(p)\n",
    "            driver.get(url)\n",
    "            html=driver.page_source\n",
    "            soup=BeautifulSoup(html,'html.parser')\n",
    "            for i in range(1,21): # 한 페이지 내, (max: 20개) 줄 단위 iteration \n",
    "                yn=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[9]').text\n",
    "                if  yn.strip()!='예정': # [신규상장]탭 > '첫날종가(원)' != '예정' 인 경우 스크랩 \n",
    "                    name=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[1]/a')\n",
    "                    name_list.append(name.text)\n",
    "                    name.send_keys(Keys.CONTROL + '\\n') # '새 창으로 보기'\n",
    "                    driver.switch_to.window(driver.window_handles[1]) # '새 창으로 탭 전환'\n",
    "                    code=driver.find_element_by_xpath('/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[2]/tbody/tr[2]/td[4]').text\n",
    "                    code_list.append(code.strip())\n",
    "                    driver.close() # 켜진 '새 창' 닫기\n",
    "                    driver.switch_to.window(driver.window_handles[0])\n",
    "        except:\n",
    "            print(name_list)\n",
    "            break\n",
    "\n",
    "    # create code df\n",
    "    mCols=[]\n",
    "    code_df=pd.DataFrame(mCols)\n",
    "\n",
    "    code_df['name']=name_list\n",
    "    code_df['code']=code_list\n",
    "\n",
    "    today=datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "#     code_df.to_csv(f'기업리스트트.csv',encoding='utf-8', index=False)\n",
    "    code_df.to_csv(f'기업리스트.csv',encoding='utf-8')    # (수정1020) 오타수정 \n",
    "    \n",
    "    return name_list, code_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial search list\n",
    "\n",
    "# def create_pstock_initial_search_list():\n",
    "def create_pstock_initial_search_list(name_list, ):\n",
    "    \n",
    "    new_stocks_1=[]\n",
    "    new_stocks_2=[]\n",
    "    new_stocks=name_list\n",
    "    for index,new_name in enumerate(new_stocks):\n",
    "        if '(유가' in new_name or '(구' in new_name:\n",
    "            new_name=new_name.split('(')[0]\n",
    "            new_stocks_1.append(new_name)\n",
    "        elif '스팩' in new_name and '호' in new_name:\n",
    "            new_name=new_name.split('스팩')\n",
    "            new_stocks_2.append(new_name)\n",
    "        else:\n",
    "            new_stocks_1.append(new_name)\n",
    "    new_stocksss=new_stocks_1+new_stocks_2\n",
    "    \n",
    "    return new_stocksss, new_stocks_1, new_stocks_2\n",
    "\n",
    "def create_naver_initial_search_list():\n",
    "    code_df=pd.read_csv('기업리스트.csv',encoding='utf-8',index_col=[0], dtype=df_dtype)\n",
    "    naver_code_list=code_df['code'].tolist()\n",
    "    naver_name_list=code_df['name'].tolist() # == name_list ( in ln 8)\n",
    "    \n",
    "    return naver_name_list, naver_code_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 함수\n",
    "\n",
    "# def pstock_search():\n",
    "def pstock_search(pstock_url, new_stocks_1, new_stocks_2):\n",
    "    driver.get(pstock_url)\n",
    "    p_search=driver.find_element_by_xpath('//*[@id=\"head_main\"]')\n",
    "    p_search.clear()\n",
    "# ===============================================================\n",
    "# new_stocks_1 : 기업명 // new_stocks_2 : '스팩' 포함 기업명\n",
    "# ===============================================================\n",
    "\n",
    "    if new_name in new_stocks_1:\n",
    "        p_search.send_keys(new_name)\n",
    "        driver.find_element_by_xpath('//*[@id=\"up_win\"]/table[2]/tbody/tr[1]/td[2]/table/tbody/tr/td[3]/table/tbody/tr[2]/td/table/tbody/tr/td[4]/input').click()\n",
    "# =============================================================================\n",
    "# 분리해서 검색하고, [기업명,ㅁ호] 중 기업명을 검색하여 ㅁ호를 포함한 이름을 선택\n",
    "# =============================================================================\n",
    "\n",
    "    elif new_name in new_stocks_2:\n",
    "        p_search.send_keys(new_name[0])    \n",
    "        driver.find_element_by_xpath('//*[@id=\"up_win\"]/table[2]/tbody/tr[1]/td[2]/table/tbody/tr/td[3]/table/tbody/tr[2]/td/table/tbody/tr/td[4]/input').click()\n",
    "        html=driver.page_source\n",
    "        i=2\n",
    "        while True:\n",
    "            name=driver.find_element_by_xpath(f'/html/body/center/table/tbody/tr[2]/td[2]/table[2]/tbody/tr[3]/td[2]/table[2]/tbody/tr[{i}]/td[1]/a').text\n",
    "            if new_name[1] in name:\n",
    "                company=driver.find_element_by_xpath(f'/html/body/center/table/tbody/tr[2]/td[2]/table[2]/tbody/tr[3]/td[2]/table[2]/tbody/tr[{i}]/td[1]/a').click()\n",
    "                break\n",
    "            else:\n",
    "                i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naver_search():\n",
    "    \"\"\"\n",
    "    'searched.append(n)'\n",
    "    : '검색기업' 결과가 나오지 않은 경우, 'n'=='검색되지 못한 기업이름'을 append 후, 에러시 출력에 사용\n",
    "    \"\"\"\n",
    "    searched=[]\n",
    "    driver.get(naver_url+str(code))\n",
    "    n=driver.find_element_by_xpath('//*[@id=\"middle\"]/div[1]/div[1]/h2/a').text\n",
    "    searched.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파싱 함수\n",
    "def pstock_parsing():\n",
    "    html=driver.page_source\n",
    "    soup=BeautifulSoup(html,'html.parser')\n",
    "    tbodys=soup.find_all('tbody')\n",
    "    for i in range(len(tbodys)-1,0,-1):\n",
    "        if soup.find_all('tbody')[i].find_all('tr')[-1].find_all('td')[0].text=='상장예정 주식수':\n",
    "            circulation_stocks=soup.find_all('tbody')[i].find_all('tr')[-3].find_all('td')[1].text.strip() # 유통가능주식수 \n",
    "            circulation_share=soup.find_all('tbody')[i].find_all('tr')[-3].find_all('td')[2].text.strip() # 유통가능지분율\n",
    "            new_listing_stocks=soup.find_all('tbody')[i].find_all('tr')[-1].find_all('td')[1].text.strip() # 상장예정주식수\n",
    "            new_listing_share=soup.find_all('tbody')[i].find_all('tr')[-1].find_all('td')[2].text.strip() # 상장예정지분율\n",
    "    \n",
    "    for j in range(len(tbodys)):\n",
    "        try:\n",
    "            if soup.find_all('tbody')[j].find_all('tr')[6].find_all('td')[0].text=='확정공모가':\n",
    "                offering_price=soup.find_all('tbody')[j].find_all('tr')[6].find_all('td')[1].text[:-5]\n",
    "        except:\n",
    "            continue \n",
    "    \n",
    "    circulation_price=int(re.sub('[,]','',circulation_stocks))*int(re.sub('[,]','',offering_price)) # 총유통가능금액 = 확정공모가 * 유통가능주식수\n",
    "    tot_price=int(re.sub('[,]','',new_listing_stocks))*int(re.sub('[,]','',offering_price)) # 시가총액 = 확정공모가 * 상장예정주식수\n",
    "    \n",
    "    circulation_stocks_list.append(circulation_stocks)\n",
    "    circulation_share_list.append(circulation_share)\n",
    "    circulation_price_list.append(circulation_price)\n",
    "    new_listing_stocks_list.append(new_listing_stocks)\n",
    "    new_listing_share_list.append(new_listing_share)\n",
    "    tot_price_list.append(tot_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naver_parsing():\n",
    "    tmp_price_list=[]\n",
    "    tmp_date_list=[]\n",
    "    \n",
    "    driver.get(naver_url+str(code)) # '네이버 금융' 기본 url + 공모주식코드\n",
    "    #== 첫 화면 '종목명' 확인용 \n",
    "    print(driver.find_element_by_xpath('//*[@id=\"middle\"]/div[1]/div[1]/h2/a').text)\n",
    "    #==\n",
    "\n",
    "    driver.find_element_by_xpath('//*[@id=\"content\"]/ul/li[2]/a').click() # 시세 탭 클릭 \n",
    "    iframes=driver.find_elements_by_tag_name('iframe') # *** iframe이 다수 \n",
    "    driver.switch_to.frame(iframes[-2]) # <<< iframe 중 '일별시세'의 위치가 뒤에서 2번쨰\n",
    "\n",
    "    html=driver.page_source\n",
    "    soup=BeautifulSoup(html,'html.parser')\n",
    "    pages=soup.find('table',class_='Nnavi').find_all('td') # 페이지 네비 칸 전체 파싱 \n",
    "\n",
    "    end_num=0\n",
    "    if len(pages)!=1: # 1개 페이지 이상인 경우 >>> \n",
    "        driver.find_element_by_class_name('pgRR').click() # 페이지 네비 '맨뒤' 클릭\n",
    "        cell_nums=[3,4,5,6,7,11,12,13,14,15] # 일별시세 내 '맨뒤' 내용 10개에 해당하는 idx 칸 번호\n",
    "        try:\n",
    "            for i in cell_nums: # 첫번쨰 칸 부터 훑어 내려와서 \n",
    "                price=driver.find_element_by_xpath(f'/html/body/table[1]/tbody/tr[{i}]/td[7]/span').text # <<< (위치001)\n",
    "                #date=driver.find_element_by_xpath(f'/html/body/table[1]/tbody/tr[{i}]/td[1]/span').text\n",
    "                prev_i=i\n",
    "                tmp_price_list.append(price) # 가격 정보를 쭉 - append 하고 \n",
    "                #tmp_date_list.append(date)\n",
    "        except: # try에서 막힌 경우 >>> '가격'정보가 없어서 파싱 예외처리 나면 (위치001), 내려와서\n",
    "            first_price=tmp_price_list[-1] # 마지막 가격 정보 == 첫날 종가 \n",
    "            first_date=driver.find_element_by_xpath(f'/html/body/table[1]/tbody/tr[{prev_i}]/td[1]/span').text # 상장첫날 날짜\n",
    "            first_price_list.append(first_price) \n",
    "            print(first_price)\n",
    "    else: #  페이지가 1개 뿐인 경우 >>> 바로 목록내 컨텐츠로 \n",
    "        cell_nums=[3,4,5,6,7,11,12,13,14,15]\n",
    "        try:\n",
    "            for i in cell_nums:\n",
    "                price=driver.find_element_by_xpath(f'/html/body/table[1]/tbody/tr[{i}]/td[7]/span').text\n",
    "#                 date=driver.find_element_by_xpath(f'/html/body/table[1]/tbody/tr[{i}]/td[1]/span').text\n",
    "                prev_i=i\n",
    "                tmp_price_list.append(price)\n",
    "        except:\n",
    "            first_price=tmp_price_list[-1]\n",
    "            first_date=driver.find_element_by_xpath(f'/html/body/table[1]/tbody/tr[{prev_i}]/td[1]/span').text\n",
    "            first_price_list.append(first_price)\n",
    "            print(first_price)\n",
    "    \n",
    "    \n",
    "    n_dates=[]\n",
    "    date=datetime.strptime(first_date,'%Y.%m.%d')\n",
    "    for d in range(3):\n",
    "        date=date+timedelta(weeks=4)    \n",
    "        n_date=date.strftime('%Y.%m.%d')\n",
    "        n_dates.append(n_date)\n",
    "        print(n_date)\n",
    "    \n",
    "    return first_price_list, first_date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df\n",
    "def create_df():\n",
    "    mCols=[]\n",
    "    p_df=pd.DataFrame(mCols)\n",
    "    \n",
    "    p_df['기업명']=search_list\n",
    "    p_df['유통가능주식수']=circulation_stocks_list\n",
    "    p_df['유통가능지분율']=circulation_share_list\n",
    "    p_df['유통가능금액']=circulation_price_list\n",
    "    p_df['상장예정주식수']=new_listing_stocks_list\n",
    "    p_df['상장예정지분율']=new_listing_share_list\n",
    "    p_df['시가총액']=tot_price_list\n",
    "    p_df['상장첫날거래량']=first_price_list\n",
    "    \n",
    "    today=datetime.today().strftime('%Y%m%d')\n",
    "    \n",
    "#     today_note=open('date_info.txt','w',encoding='utf-8')\n",
    "#     print(f'{today}',file=today_note)\n",
    "#     today_note.close()\n",
    "    \n",
    "    p_df.to_csv('pstock_naver.csv',encoding='utf-8')\n",
    "    p_df.to_csv(save_dir+f'pstock_naver_{today}.csv',encoding='utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create failed note\n",
    "def failed_note():    \n",
    "    today=datetime.today().strftime('%y%m%d')\n",
    "    failed_note=open(save_dir+f'failed/failed_note_{today}.txt','w',encoding='utf-8')\n",
    "    print(f'pstock\\n 검색불가 : {pstock_search_failed} \\n파싱불가 : {pstock_parsing_failed}', file=failed_note)\n",
    "    print(f'\\n naver \\n 검색불가 : {naver_search_failed} \\n파싱불가 : {naver_parsing_failed}', file=failed_note)\n",
    "    \n",
    "    failed_note.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_list=[]\n",
    "\n",
    "pstock_search_failed=[]\n",
    "pstock_parsing_failed=[]\n",
    "\n",
    "naver_search_failed=[]\n",
    "naver_parsing_failed=[]\n",
    "\n",
    "company_name_list=[]\n",
    "\n",
    "circulation_stocks_list=[]\n",
    "circulation_share_list=[]\n",
    "circulation_price_list=[]\n",
    "\n",
    "new_listing_stocks_list=[]\n",
    "new_listing_share_list=[]\n",
    "tot_price_list=[]\n",
    "\n",
    "first_price_list=[]\n",
    "first_date_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피플바이오\n",
      "423,111\n",
      "2020.11.16\n",
      "2020.12.14\n",
      "2021.01.11\n",
      "빅히트\n",
      "423,111\n",
      "2020.11.12\n",
      "2020.12.10\n",
      "2021.01.07\n",
      "넥스틴\n",
      "423,111\n",
      "2020.11.05\n",
      "2020.12.03\n",
      "2020.12.31\n",
      "원방테크\n",
      "1,530,069\n",
      "2020.10.22\n",
      "2020.11.19\n",
      "2020.12.17\n",
      "엔에이치스팩17호\n",
      "551,120\n",
      "2020.10.21\n",
      "2020.11.18\n",
      "2020.12.16\n",
      "비나텍\n",
      "0\n",
      "2013.07.29\n",
      "2013.08.26\n",
      "2013.09.23\n",
      "박셀바이오\n",
      "4,090,940\n",
      "2020.10.20\n",
      "2020.11.17\n",
      "2020.12.15\n",
      "비비씨\n",
      "2,415,082\n",
      "2020.10.19\n",
      "2020.11.16\n",
      "2020.12.14\n",
      "교보10호스팩\n",
      "227,158\n",
      "2020.10.16\n",
      "2020.11.13\n",
      "2020.12.11\n",
      "핌스\n",
      "5,871,649\n",
      "2020.10.16\n",
      "2020.11.13\n",
      "2020.12.11\n",
      "압타머사이언스\n",
      "이오플로우\n",
      "6,672,023\n",
      "2020.10.12\n",
      "2020.11.09\n",
      "2020.12.07\n",
      "카카오게임즈\n",
      "561,750\n",
      "2020.10.08\n",
      "2020.11.05\n",
      "2020.12.03\n",
      "피엔케이피부임상연구센타\n",
      "8,304,697\n",
      "2020.10.07\n",
      "2020.11.04\n",
      "2020.12.02\n",
      "코람코에너지리츠\n",
      "2,881,153\n",
      "2020.09.28\n",
      "2020.10.26\n",
      "2020.11.23\n",
      "미래에셋대우스팩 5호\n",
      "459,818\n",
      "2020.09.25\n",
      "2020.10.23\n",
      "2020.11.20\n",
      "아이디피\n",
      "9,251,446\n",
      "2020.09.21\n",
      "2020.10.19\n",
      "2020.11.16\n",
      "셀레믹스\n",
      "11,903,741\n",
      "2020.09.18\n",
      "2020.10.16\n",
      "2020.11.13\n",
      "미투젠\n",
      "5,518,960\n",
      "2020.09.15\n",
      "2020.10.13\n",
      "2020.11.10\n",
      "브랜드엑스코퍼레이션\n",
      "4,135,892\n",
      "2020.09.10\n",
      "2020.10.08\n",
      "2020.11.05\n",
      "영림원소프트랩\n",
      "6,132,668\n",
      "2020.09.09\n",
      "2020.10.07\n",
      "2020.11.04\n",
      "한국파마\n",
      "14,406,068\n",
      "2020.09.07\n",
      "2020.10.05\n",
      "2020.11.02\n",
      "제이알글로벌리츠\n",
      "4,782,397\n",
      "2020.09.04\n",
      "2020.10.02\n",
      "2020.10.30\n",
      "이루다\n",
      "10,221,394\n",
      "2020.09.03\n",
      "2020.10.01\n",
      "2020.10.29\n",
      "이지스레지던스리츠\n",
      "2,356,867\n",
      "2020.09.02\n",
      "2020.09.30\n",
      "2020.10.28\n",
      "미래에셋맵스리츠\n",
      "1,924,775\n",
      "2020.09.02\n",
      "2020.09.30\n",
      "2020.10.28\n",
      "와이팜\n",
      "21,163,861\n",
      "2020.08.28\n",
      "2020.09.25\n",
      "2020.10.23\n",
      "이엔드디\n",
      "1,000\n",
      "2013.07.29\n",
      "2013.08.26\n",
      "2013.09.23\n",
      "엠투아이\n",
      "5,639,452\n",
      "2020.08.26\n",
      "2020.09.23\n",
      "2020.10.21\n",
      "에이치엠씨제4호스팩\n",
      "423,111\n",
      "2020.08.26\n",
      "2020.09.23\n",
      "2020.10.21\n",
      "****** Pstock Search Failed : ['SK바이오팜', '엔에이치프라임리츠', ['IBKS', '13호'], ['IBKS', '14호'], ['케이프이에스', '4호'], ['한화플러스', '1호'], ['IBKS', '12호'], 'SK바이오팜', '엔에이치프라임리츠', ['IBKS', '13호'], ['IBKS', '14호'], ['케이프이에스', '4호'], ['한화플러스', '1호'], ['IBKS', '12호']]\n",
      "****** Pstock Parsing Failed: ['코람코에너지플러스리츠', '제이알글로벌리츠', '이지스레지던스리츠', '미래에셋맵스리츠1호', '이지스밸류플러스리츠', ['엔에이치', '17호'], ['교보', '10호'], ['미래에셋대우', '5호'], ['에이치엠씨아이비', '4호'], ['하나금융', '16호'], ['엔에이치', '16호'], ['이베스트', '5호'], ['에스케이', '6호'], ['신영', '6호'], ['하나금융', '15호'], ['케이비', '20호'], ['엔에이치', '15호'], ['하이', '5호'], ['대신밸런스', '8호'], ['유안타', '6호'], '코람코에너지플러스리츠', '제이알글로벌리츠', '이지스레지던스리츠', '미래에셋맵스리츠1호', '이지스밸류플러스리츠', ['엔에이치', '17호'], ['교보', '10호'], ['미래에셋대우', '5호'], ['에이치엠씨아이비', '4호'], ['하나금융', '16호'], ['엔에이치', '16호'], ['이베스트', '5호'], ['에스케이', '6호'], ['신영', '6호'], ['하나금융', '15호'], ['케이비', '20호'], ['엔에이치', '15호'], ['하이', '5호'], ['대신밸런스', '8호'], ['유안타', '6호']]\n",
      "****** Naver Search Failed : []\n",
      "****** Naver Parsing Failed: ['피플바이오', '핌스', '압타머사이언스', '압타머사이언스']\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 크롤링 수행    -    가장 처음 시작시 수행\n",
    "# ================================================================\n",
    "\n",
    "driver=webdriver.Chrome(chrome_dir)\n",
    "# 1.0.1\n",
    "name_list,code_list=create_initial_search_list()\n",
    "\n",
    "# 2.p.1\n",
    "new_stocksss,new_stocks_1,new_stocks_2=create_pstock_initial_search_list()\n",
    "# 2.n.1\n",
    "naver_name_list,naver_code_list=create_naver_initial_search_list()\n",
    "\n",
    "# pstock\n",
    "\n",
    "for new_name in new_stocksss:\n",
    "    try:\n",
    "        pstock_search()     # search 함수 실행 # # 2.p.2\n",
    "        name=driver.find_element_by_xpath('/html/body/center/table/tbody/tr[2]/td[2]/table/tbody/tr[1]/td[1]/table[6]/tbody/tr/td[2]/table/tbody/tr[2]/td[1]/b').text.strip()\n",
    "        search_list.append(name)\n",
    "    except:\n",
    "        search_list.append(np.nan)\n",
    "        pstock_search_failed.append(new_name)\n",
    "        circulation_stocks_list.append(np.nan)\n",
    "        circulation_share_list.append(np.nan)\n",
    "        circulation_price_list.append(np.nan)\n",
    "        new_listing_stocks_list.append(np.nan)\n",
    "        new_listing_share_list.append(np.nan)\n",
    "        tot_price_list.append(np.nan)\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        pstock_parsing()     # # 2.p.3\n",
    "        company_name_list.append(new_name)\n",
    "    except:\n",
    "        pstock_parsing_failed.append(new_name)\n",
    "        circulation_stocks_list.append(np.nan)\n",
    "        circulation_share_list.append(np.nan)\n",
    "        circulation_price_list.append(np.nan)\n",
    "        new_listing_stocks_list.append(np.nan)\n",
    "        new_listing_share_list.append(np.nan)\n",
    "        tot_price_list.append(np.nan)        \n",
    "        continue\n",
    "        \n",
    "# naver\n",
    "\n",
    "naver_dict=dict(zip(naver_code_list,naver_name_list))\n",
    "\n",
    "# for code in naver_code_list[:30]:    # <<< (1020)\n",
    "for code in naver_code_list:\n",
    "    try:\n",
    "        naver_search()        # # 2.n.2\n",
    "    except:\n",
    "        s_failed_name=naver_dict.get(code)\n",
    "        naver_search_failed.append(s_failed_name)\n",
    "        first_price_list.append(np.nan)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        naver_parsing()      # # 2.n.3\n",
    "    except:\n",
    "        p_failed_name=naver_dict.get(code)\n",
    "        naver_parsing_failed.append(p_failed_name)\n",
    "        first_price_list.append(np.nan)\n",
    "        continue\n",
    "        \n",
    "        \n",
    "create_df()        # 3.1.1\n",
    "failed_note()      # 3.1.2\n",
    "        \n",
    "    \n",
    "print(f'****** Pstock Search Failed : {pstock_search_failed}')\n",
    "print(f'****** Pstock Parsing Failed: {pstock_parsing_failed}')\n",
    "print(f'****** Naver Search Failed : {naver_search_failed}')\n",
    "print(f'****** Naver Parsing Failed: {naver_parsing_failed}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
