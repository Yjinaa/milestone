{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# v3.0 수정사항\n",
    "# 과거 df 불러오는 방식을 txt 저장 방식에서\n",
    "# 내부 저장소를 이용하여 갱신하는 방식으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from itertools import count\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import numpy as np\n",
    "\n",
    "# import glob\n",
    "# from pyexcel.cookbook import merge_all_to_a_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_dir='C:/Yeajin/chromedriver_win32/chromedriver'\n",
    "save_dir='C:/Yeajin/리얼데이터/마일스톤/crawling/'\n",
    "\n",
    "pstock_url='http://www.pstock.co.kr/2005pstock/main.asp'\n",
    "naver_url='https://finance.naver.com/item/main.nhn?code='\n",
    "url_38='http://www.38.co.kr/html/fund/index.htm?o=nw&page='\n",
    "\n",
    "df_dtype={'code':str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update search list\n",
    "\n",
    "def update_search_list():\n",
    "    todo_names=[]\n",
    "    todo_codes=[]\n",
    "    df=pd.read_csv('기업리스트.csv',encoding='utf-8',index_col=[0],dtype={'code':str})\n",
    "    # old_list=df['name'].tolist()\n",
    "    old_name_list=df['name'].tolist()\n",
    "    old_code_list=df['code'].tolist()\n",
    "\n",
    "    fin=False\n",
    "\n",
    "    for p in count(1):\n",
    "        driver.get(url_38+str(p))\n",
    "        for i in range(1,21):\n",
    "            new_yn=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[9]')\n",
    "            if new_yn.text.strip()!='예정':\n",
    "                todo_name=driver.find_element_by_xpath(f'/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[4]/tbody/tr[2]/td/table/tbody/tr[{i}]/td[1]/a')\n",
    "                #####++======================================\n",
    "                if todo_name.text.strip() in old_name_list:   ## old_name_list?\n",
    "                    fin=True\n",
    "                    print('업데이트가 완료되었습니다.')\n",
    "                    break\n",
    "                else:\n",
    "                    todo_names.append(todo_name.text.strip())\n",
    "                    todo_name.send_keys(Keys.CONTROL+'\\n')\n",
    "                    driver.switch_to.window(driver.window_handles[1])\n",
    "                    todo_code=driver.find_element_by_xpath('/html/body/table[3]/tbody/tr/td/table[1]/tbody/tr/td[1]/table[2]/tbody/tr[2]/td[4]').text.strip()\n",
    "                    todo_codes.append(todo_code.strip())\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[0])\n",
    "        if fin==True:\n",
    "            break\n",
    "\n",
    "    mCols=[]        \n",
    "    updated_df=pd.DataFrame(mCols)\n",
    "\n",
    "    n_name_list=todo_names+old_name_list\n",
    "    n_code_list=todo_codes+old_code_list\n",
    "\n",
    "    updated_df['name']=n_name_list\n",
    "    updated_df['code']=n_code_list\n",
    "\n",
    "    updated_df.to_csv('기업리스트.csv',encoding='utf-8')\n",
    "    \n",
    "    return todo_names, todo_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create updated search list\n",
    "\n",
    "def create_pstock_updated_search_list():\n",
    "    \n",
    "    new_stocks_1=[]\n",
    "    new_stocks_2=[]\n",
    "    new_stocks=todo_names\n",
    "    for index,new_name in enumerate(new_stocks):\n",
    "        if '(유가' in new_name or '(구' in new_name:\n",
    "            new_name=new_name.split('(')[0]\n",
    "            new_stocks_1.append(new_name)\n",
    "        elif '스팩' in new_name and '호' in new_name:\n",
    "            new_name=new_name.split('스팩')\n",
    "            new_stocks_2.append(new_name)\n",
    "        else:\n",
    "            new_stocks_1.append(new_name)\n",
    "    new_stocksss=new_stocks_1+new_stocks_2\n",
    "    \n",
    "    return new_stocksss,new_stocks_1, new_stocks_2\n",
    "\n",
    "def create_naver_updated_search_list():\n",
    "    naver_name_list=todo_names\n",
    "    naver_code_list=todo_codes\n",
    "    print(todo_names,todo_codes)\n",
    "    \n",
    "    return naver_name_list, naver_code_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 함수\n",
    "\n",
    "def pstock_search():\n",
    "    \n",
    "#     new_stocksss=create_pstock_updated_search_list()[0]\n",
    "#     new_stocks_1=create_pstock_updated_search_list()[1]\n",
    "#     new_stocks_2=create_pstock_updated_search_list()[2]\n",
    "    \n",
    "    driver.get(pstock_url)\n",
    "    p_search=driver.find_element_by_xpath('//*[@id=\"head_main\"]')\n",
    "    p_search.clear()\n",
    "# ===============================================================\n",
    "# new_stocks_1 : 기업명 // new_stocks_2 : '스팩' 포함 기업명\n",
    "# ===============================================================\n",
    "\n",
    "    if new_name in new_stocks_1:\n",
    "        p_search.send_keys(new_name)\n",
    "        driver.find_element_by_xpath('//*[@id=\"up_win\"]/table[2]/tbody/tr[1]/td[2]/table/tbody/tr/td[3]/table/tbody/tr[2]/td/table/tbody/tr/td[4]/input').click()\n",
    "# =============================================================================\n",
    "# 분리해서 검색하고, [기업명,ㅁ호] 중 기업명을 검색하여 ㅁ호를 포함한 이름을 선택\n",
    "# =============================================================================\n",
    "\n",
    "    elif new_name in new_stocks_2:\n",
    "        p_search.send_keys(new_name[0])    \n",
    "        driver.find_element_by_xpath('//*[@id=\"up_win\"]/table[2]/tbody/tr[1]/td[2]/table/tbody/tr/td[3]/table/tbody/tr[2]/td/table/tbody/tr/td[4]/input').click()\n",
    "        html=driver.page_source\n",
    "        i=2\n",
    "        while True:\n",
    "            name=driver.find_element_by_xpath(f'/html/body/center/table/tbody/tr[2]/td[2]/table[2]/tbody/tr[3]/td[2]/table[2]/tbody/tr[{i}]/td[1]/a').text\n",
    "            if new_name[1] in name:\n",
    "                company=driver.find_element_by_xpath(f'/html/body/center/table/tbody/tr[2]/td[2]/table[2]/tbody/tr[3]/td[2]/table[2]/tbody/tr[{i}]/td[1]/a').click()\n",
    "                break\n",
    "            else:\n",
    "                i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naver_search():\n",
    "    searched=[]\n",
    "    driver.get(naver_url+str(code))\n",
    "    n=driver.find_element_by_xpath('//*[@id=\"middle\"]/div[1]/div[1]/h2/a').text\n",
    "    searched.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파싱 함수\n",
    "def pstock_parsing():\n",
    "    html=driver.page_source\n",
    "    soup=BeautifulSoup(html,'html.parser')\n",
    "    tbodys=soup.find_all('tbody')\n",
    "    for i in range(len(tbodys)-1,0,-1):\n",
    "        if soup.find_all('tbody')[i].find_all('tr')[-1].find_all('td')[0].text=='상장예정 주식수':\n",
    "            circulation_stocks=soup.find_all('tbody')[i].find_all('tr')[-3].find_all('td')[1].text.strip()\n",
    "            circulation_share=soup.find_all('tbody')[i].find_all('tr')[-3].find_all('td')[2].text.strip()\n",
    "            new_listing_stocks=soup.find_all('tbody')[i].find_all('tr')[-1].find_all('td')[1].text.strip()\n",
    "            new_listing_share=soup.find_all('tbody')[i].find_all('tr')[-1].find_all('td')[2].text.strip()\n",
    "    \n",
    "    for j in range(len(tbodys)):\n",
    "        try:\n",
    "            if soup.find_all('tbody')[j].find_all('tr')[6].find_all('td')[0].text=='확정공모가':\n",
    "                offering_price=soup.find_all('tbody')[j].find_all('tr')[6].find_all('td')[1].text[:-5]\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    circulation_price=int(re.sub('[,]','',circulation_stocks))*int(re.sub('[,]','',offering_price))\n",
    "    tot_price=int(re.sub('[,]','',new_listing_stocks))*int(re.sub('[,]','',offering_price))\n",
    "    \n",
    "    circulation_stocks_list.append(circulation_stocks)\n",
    "    circulation_share_list.append(circulation_share)\n",
    "    circulation_price_list.append(circulation_price)\n",
    "    new_listing_stocks_list.append(new_listing_stocks)\n",
    "    new_listing_share_list.append(new_listing_share)\n",
    "    tot_price_list.append(tot_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naver_parsing():\n",
    "    tmp_price_list=[]\n",
    "    tmp_date_list=[]\n",
    "    \n",
    "    driver.get(naver_url+str(code))\n",
    "    #==\n",
    "#     print(driver.find_element_by_xpath('//*[@id=\"middle\"]/div[1]/div[1]/h2/a').text)\n",
    "    #==\n",
    "\n",
    "    driver.find_element_by_xpath('//*[@id=\"content\"]/ul/li[2]/a').click()\n",
    "    iframes=driver.find_elements_by_tag_name('iframe')\n",
    "    driver.switch_to.frame(iframes[-2])\n",
    "\n",
    "    html=driver.page_source\n",
    "    soup=BeautifulSoup(html,'html.parser')\n",
    "    pages=soup.find('table',class_='Nnavi').find_all('td')\n",
    "\n",
    "    end_num=0\n",
    "    if len(pages)!=1:\n",
    "        driver.find_element_by_class_name('pgRR').click()\n",
    "        cell_nums=[3,4,5,6,7,11,12,13,14,15]\n",
    "        try:\n",
    "            for i in cell_nums:\n",
    "                price=driver.find_element_by_xpath(f'/html/body/table[1]/tbody/tr[{i}]/td[7]/span').text\n",
    "                #date=driver.find_element_by_xpath(f'/html/body/table[1]/tbody/tr[{i}]/td[1]/span').text\n",
    "                prev_i=i\n",
    "                tmp_price_list.append(price)\n",
    "                #tmp_date_list.append(date)\n",
    "        except:\n",
    "            first_price=tmp_price_list[-1]\n",
    "            first_date=driver.find_element_by_xpath(f'/html/body/table[1]/tbody/tr[{prev_i}]/td[1]/span').text\n",
    "            first_price_list.append(first_price)\n",
    "#             print(first_price)\n",
    "    else:\n",
    "        cell_nums=[3,4,5,6,7,11,12,13,14,15]\n",
    "        try:\n",
    "            for i in cell_nums:\n",
    "                price=driver.find_element_by_xpath(f'/html/body/table[1]/tbody/tr[{i}]/td[7]/span').text\n",
    "#                 date=driver.find_element_by_xpath(f'/html/body/table[1]/tbody/tr[{i}]/td[1]/span').text\n",
    "                prev_i=i\n",
    "                tmp_price_list.append(price)\n",
    "        except:\n",
    "            first_price=tmp_price_list[-1]\n",
    "            first_date=driver.find_element_by_xpath(f'/html/body/table[1]/tbody/tr[{prev_i}]/td[1]/span').text\n",
    "            first_price_list.append(first_price)\n",
    "#             print(first_price)\n",
    "    \n",
    "    \n",
    "    n_dates=[]\n",
    "    date=datetime.strptime(first_date,'%Y.%m.%d')\n",
    "    for d in range(3):\n",
    "        date=date+timedelta(weeks=4)    \n",
    "        n_date=date.strftime('%Y.%m.%d')\n",
    "        n_dates.append(n_date)\n",
    "#         print(n_date)\n",
    "    \n",
    "    return first_price_list, first_date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update df\n",
    "def update_df():\n",
    "    mCols=[]\n",
    "    p_df=pd.DataFrame(mCols) \n",
    "    \n",
    "    p_df['기업명']=search_list\n",
    "    p_df['유통가능주식수']=circulation_stocks_list\n",
    "    p_df['유통가능지분율']=circulation_share_list\n",
    "    p_df['유통가능금액']=circulation_price_list\n",
    "    p_df['상장예정주식수']=new_listing_stocks_list\n",
    "    p_df['상장예정지분율']=new_listing_share_list\n",
    "    p_df['시가총액']=tot_price_list\n",
    "    p_df['상장첫날거래량']=first_price_list\n",
    "    \n",
    "    today=datetime.today().strftime('%Y%m%d')\n",
    "    \n",
    "    origin_df=pd.read_csv('pstock_naver.csv',encoding='utf-8',index_col=[0])\n",
    "    new_df=pd.concat([p_df,origin_df])\n",
    "    \n",
    "#     last_point_note=open('date_info.txt','r',encoding='utf-8')\n",
    "#     last_point=last_point_note.read().rstrip('\\n')\n",
    "#     origin_df=pd.read_csv(save_dir+f'pstock_naver_{last_point}.csv',encoding='utf-8',\n",
    "#                           index_col=[0])\n",
    "    \n",
    "#     new_df=pd.concat([p_df,origin_df])\n",
    "    \n",
    "#     today_note=open('date_info.txt','w',encoding='utf-8')\n",
    "#     print(f'{today}',file=today_note)\n",
    "#     today_note.close()\n",
    "    \n",
    "    new_df.to_csv('pstock_naver.csv',encoding='utf-8')\n",
    "    new_df.to_csv(save_dir+f'pstock_naver_{today}.csv',encoding='utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create failed note\n",
    "def failed_note():    \n",
    "    today=datetime.today().strftime('%y%m%d')\n",
    "    failed_note=open(save_dir+f'failed_note_{today}.txt','w',encoding='utf-8')\n",
    "    print(f'pstock\\n 검색불가 : {pstock_search_failed} \\n파싱불가 : {pstock_parsing_failed}', file=failed_note)\n",
    "    print(f'\\n naver \\n 검색불가 : {naver_search_failed} \\n파싱불가 : {naver_parsing_failed}', file=failed_note)\n",
    "\n",
    "    failed_note.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_list=[]\n",
    "\n",
    "pstock_search_failed=[]\n",
    "pstock_parsing_failed=[]\n",
    "\n",
    "naver_search_failed=[]\n",
    "naver_parsing_failed=[]\n",
    "\n",
    "company_name_list=[]\n",
    "\n",
    "circulation_stocks_list=[]\n",
    "circulation_share_list=[]\n",
    "circulation_price_list=[]\n",
    "\n",
    "new_listing_stocks_list=[]\n",
    "new_listing_share_list=[]\n",
    "tot_price_list=[]\n",
    "\n",
    "first_price_list=[]\n",
    "first_date_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "업데이트가 완료되었습니다.\n",
      "['피플바이오', '빅히트(유가)', '넥스틴', '원방테크', '엔에이치스팩17호'] ['304840', '352820', '348210', '053080', '359090']\n",
      "피플바이오\n",
      "5,547,457\n",
      "2020.11.16\n",
      "2020.12.14\n",
      "2021.01.11\n",
      "빅히트\n",
      "6,557,212\n",
      "2020.11.12\n",
      "2020.12.10\n",
      "2021.01.07\n",
      "넥스틴\n",
      "299,812\n",
      "2020.11.05\n",
      "2020.12.03\n",
      "2020.12.31\n",
      "원방테크\n",
      "1,530,069\n",
      "2020.10.22\n",
      "2020.11.19\n",
      "2020.12.17\n",
      "엔에이치스팩17호\n",
      "551,120\n",
      "2020.10.21\n",
      "2020.11.18\n",
      "2020.12.16\n",
      "****** Pstock Search Failed : []\n",
      "****** Pstock Parsing Failed: [['엔에이치', '17호']]\n",
      "****** Naver Search Failed : []\n",
      "****** Naver Parsing Failed: []\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 크롤링 수행   -   업데이트 시 수행\n",
    "# ================================================================\n",
    "\n",
    "driver=webdriver.Chrome(chrome_dir)\n",
    "\n",
    "todo_names,todo_codes=update_search_list()\n",
    "\n",
    "new_stocksss,new_stocks_1,new_stocks_2=create_pstock_updated_search_list()\n",
    "\n",
    "naver_name_list,naver_code_list=create_naver_updated_search_list()\n",
    "\n",
    "# pstock\n",
    "\n",
    "for new_name in new_stocksss:\n",
    "    try:\n",
    "        pstock_search()     # search 함수 실행\n",
    "        name=driver.find_element_by_xpath('/html/body/center/table/tbody/tr[2]/td[2]/table/tbody/tr[1]/td[1]/table[6]/tbody/tr/td[2]/table/tbody/tr[2]/td[1]/b').text.strip()\n",
    "        search_list.append(name)\n",
    "    except:\n",
    "        search_list.append(np.nan)\n",
    "        pstock_search_failed.append(new_name)\n",
    "        circulation_stocks_list.append(np.nan)\n",
    "        circulation_share_list.append(np.nan)\n",
    "        circulation_price_list.append(np.nan)\n",
    "        new_listing_stocks_list.append(np.nan)\n",
    "        new_listing_share_list.append(np.nan)\n",
    "        tot_price_list.append(np.nan)\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        pstock_parsing()\n",
    "        company_name_list.append(new_name)\n",
    "    except:\n",
    "        pstock_parsing_failed.append(new_name)\n",
    "        circulation_stocks_list.append(np.nan)\n",
    "        circulation_share_list.append(np.nan)\n",
    "        circulation_price_list.append(np.nan)\n",
    "        new_listing_stocks_list.append(np.nan)\n",
    "        new_listing_share_list.append(np.nan)\n",
    "        tot_price_list.append(np.nan)\n",
    "        continue\n",
    "        \n",
    "#     try:\n",
    "#         pstock_create_df()\n",
    "#         failed_note()\n",
    "#     except:\n",
    "#         print('오류발생!')\n",
    "\n",
    "# naver\n",
    "\n",
    "naver_dict=dict(zip(naver_code_list,naver_name_list))\n",
    "\n",
    "for code in naver_code_list:\n",
    "    try:\n",
    "        naver_search()\n",
    "    except:\n",
    "        s_failed_name=naver_dict.get(code)\n",
    "        naver_search_failed.append(s_failed_name)\n",
    "        first_price_list.append(np.nan)\n",
    "\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        naver_parsing()\n",
    "    except:\n",
    "        p_failed_name=naver_dict.get(code)\n",
    "        naver_parsing_failed.append(p_failed_name)\n",
    "        first_price_list.append(np.nan)\n",
    "        continue\n",
    "        \n",
    "update_df()\n",
    "failed_note()\n",
    "        \n",
    "        \n",
    "print(f'****** Pstock Search Failed : {pstock_search_failed}')\n",
    "print(f'****** Pstock Parsing Failed: {pstock_parsing_failed}')\n",
    "print(f'****** Naver Search Failed : {naver_search_failed}')\n",
    "print(f'****** Naver Parsing Failed: {naver_parsing_failed}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
